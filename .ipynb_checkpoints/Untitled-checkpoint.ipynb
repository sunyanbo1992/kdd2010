{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row|Anon Student Id|Problem Hierarchy|Problem Name|Problem View|Step Name|Step Start Time|First Transaction Time|Correct Transaction Time|Step End Time|Step Duration (sec)|Correct Step Duration (sec)|Error Step Duration (sec)|Correct First Attempt|Incorrects|Hints|Corrects|KC(Default)|Opportunity(Default)\n",
      "1|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG4-FIXED|1|3(x+2) = 15|2005-09-09 12:24:35.0|2005-09-09 12:24:49.0|2005-09-09 12:25:15.0|2005-09-09 12:25:15.0|40||40|0|2|3|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|1\n",
      "2|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG4-FIXED|1|x+2 = 5|2005-09-09 12:25:15.0|2005-09-09 12:25:31.0|2005-09-09 12:25:31.0|2005-09-09 12:25:31.0|16|16||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate positive; x+a=b, positive]|1~~1\n",
      "3|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|1|2-8y = -4|2005-09-09 12:25:36.0|2005-09-09 12:25:43.0|2005-09-09 12:26:12.0|2005-09-09 12:26:12.0|36||36|0|2|3|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|2\n",
      "4|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|1|-8y = -6|2005-09-09 12:26:12.0|2005-09-09 12:26:34.0|2005-09-09 12:26:34.0|2005-09-09 12:26:34.0|22|22||1|0|0|1|[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]~~[SkillRule: Remove negative coefficient; {ax/b=c, reciprocal; ax/b=c; ax=b; x/a=b}]|1~~1\n",
      "5|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|2|-7y-5 = -4|2005-09-09 12:26:38.0|2005-09-09 12:28:36.0|2005-09-09 12:28:36.0|2005-09-09 12:28:36.0|118|118||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: ax+b=c, negative; ax+b=c, negative]|3~~1\n",
      "6|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|2|-7y = 1|2005-09-09 12:28:36.0|2005-09-09 12:28:43.0|2005-09-09 12:28:51.0|2005-09-09 12:28:51.0|15||15|0|1|0|1|[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]~~[SkillRule: Remove negative coefficient; {ax/b=c, reciprocal; ax/b=c; ax=b; x/a=b}]|2~~2\n",
      "7|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|3|7y+4 = 7|2005-09-09 12:28:57.0|2005-09-09 12:29:09.0|2005-09-09 12:29:09.0|2005-09-09 12:29:09.0|12|12||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|4\n",
      "8|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|3|7y = 3|2005-09-09 12:29:09.0|2005-09-09 12:29:14.0|2005-09-09 12:29:14.0|2005-09-09 12:29:14.0|5|5||1|0|0|1|[SkillRule: Remove positive coefficient; {ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b}]~~[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]|1~~3\n",
      "9|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|4|-5+9y = -6|2005-09-09 12:29:19.0|2005-09-09 12:29:31.0|2005-09-09 12:29:31.0|2005-09-09 12:29:31.0|12|12||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: ax+b=c, negative; ax+b=c, negative]|5~~2\n",
      "10|0BrbPbwCMz|Unit ES_04, Section ES_04-1|EG40|4|9y = -1|2005-09-09 12:29:31.0|2005-09-09 12:29:36.0|2005-09-09 12:29:36.0|2005-09-09 12:29:36.0|5|5||1|0|0|1|[SkillRule: Remove positive coefficient; {ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b}]~~[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]|2~~4\n",
      "11|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|1|-7-3x = -2|2005-09-09 12:29:41.0|2005-09-09 12:30:27.0|2005-09-09 12:30:27.0|2005-09-09 12:30:27.0|46|46||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: ax+b=c, negative; ax+b=c, negative]|6~~3\n",
      "12|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|1|-7-3x+7 = -2+7|2005-09-09 12:30:27.0|2005-09-09 12:30:34.0|2005-09-09 12:30:45.0|2005-09-09 12:30:49.0|22||22|0|1|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|1\n",
      "13|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|1|-3x = 5|2005-09-09 12:30:49.0|2005-09-09 12:31:04.0|2005-09-09 12:31:04.0|2005-09-09 12:31:04.0|15|15||1|0|0|1|[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]~~[SkillRule: Remove negative coefficient; {ax/b=c, reciprocal; ax/b=c; ax=b; x/a=b}]|5~~3\n",
      "14|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|1|-3x/-3 = 5/-3|2005-09-09 12:31:04.0|2005-09-09 12:31:07.0|2005-09-09 12:31:07.0|2005-09-09 12:31:12.0|8|8||1|0|0|2|[SkillRule: Multiply/Divide; [Typein Skill: {Remove coefficient; Variable in denominator}]]|1\n",
      "15|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|2|-9 = 8y+9|2005-09-09 12:31:16.0|2005-09-09 12:31:29.0|2005-09-09 12:31:29.0|2005-09-09 12:31:29.0|13|13||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|7\n",
      "16|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|2|-9-9 = 8y+9-9|2005-09-09 12:31:29.0|2005-09-09 12:31:32.0|2005-09-09 12:31:32.0|2005-09-09 12:31:39.0|10|10||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|2\n",
      "17|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|2|-18 = 8y|2005-09-09 12:31:39.0|2005-09-09 12:31:44.0|2005-09-09 12:31:44.0|2005-09-09 12:31:44.0|5|5||1|0|0|1|[SkillRule: Remove positive coefficient; {ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b}]~~[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]|3~~6\n",
      "18|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|2|-18/8 = 8y/8|2005-09-09 12:31:44.0|2005-09-09 12:31:46.0|2005-09-09 12:31:46.0|2005-09-09 12:32:56.0|72|72||1|2|0|2|[SkillRule: Multiply/Divide; [Typein Skill: {Remove coefficient; Variable in denominator}]]|2\n",
      "19|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|3|-2-2x = 9|2005-09-09 12:33:01.0|2005-09-09 12:33:22.0|2005-09-09 12:33:32.0|2005-09-09 12:33:32.0|31||31|0|1|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: ax+b=c, negative; ax+b=c, negative]|8~~4\n",
      "20|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|3|-2-2x+2 = 9+2|2005-09-09 12:33:32.0|2005-09-09 12:33:37.0|2005-09-09 12:33:37.0|2005-09-09 12:33:40.0|8|8||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|3\n",
      "21|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|3|-2x = 11|2005-09-09 12:33:40.0|2005-09-09 12:33:46.0|2005-09-09 12:33:46.0|2005-09-09 12:33:46.0|6|6||1|0|0|1|[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]~~[SkillRule: Remove negative coefficient; {ax/b=c, reciprocal; ax/b=c; ax=b; x/a=b}]|7~~4\n",
      "22|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|3|-2x/-2 = 11/-2|2005-09-09 12:33:46.0|2005-09-09 12:33:51.0|2005-09-09 12:33:51.0|2005-09-09 12:33:55.0|9|9||1|0|0|2|[SkillRule: Multiply/Divide; [Typein Skill: {Remove coefficient; Variable in denominator}]]|3\n",
      "23|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|4+4y = -6|2005-09-09 12:33:59.0|2005-09-09 12:34:06.0|2005-09-09 12:34:06.0|2005-09-09 12:34:06.0|7|7||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|9\n",
      "24|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|4+4y-4 = -6-4|2005-09-09 12:34:06.0|2005-09-09 12:34:09.0|2005-09-09 12:34:09.0|2005-09-09 12:34:17.0|11|11||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|4\n",
      "25|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|4y = -6-4|2005-09-09 12:34:17.0|2005-09-09 12:34:25.0|2005-09-09 12:34:25.0|2005-09-09 12:34:25.0|8|8||1|0|0|1|[SkillRule: Consolidate vars with coeff; CLT]|1\n",
      "26|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|FinalAnswer|2005-09-09 12:34:25.0|2005-09-09 12:34:29.0|2005-09-09 12:34:33.0|2005-09-09 12:34:33.0|8||8|0|1|0|1|combine-like-terms-sp|1\n",
      "27|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|4y = -10|2005-09-09 12:34:33.0|2005-09-09 12:34:42.0|2005-09-09 12:34:42.0|2005-09-09 12:34:42.0|9|9||1|0|0|1|[SkillRule: Remove positive coefficient; {ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b}]~~[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]|4~~8\n",
      "28|0BrbPbwCMz|Unit ES_04, Section ES_04-2|EG40|4|4y/4 = -10/4|2005-09-09 12:34:42.0|2005-09-09 12:34:46.0|2005-09-09 12:34:46.0|2005-09-09 12:35:02.0|20|20||1|0|0|2|[SkillRule: Multiply/Divide; [Typein Skill: {Remove coefficient; Variable in denominator}]]|4\n",
      "29|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|1|-7 = -5(y+7)|2005-09-09 12:35:08.0|2005-09-09 12:36:27.0|2005-09-09 12:37:01.0|2005-09-09 12:37:01.0|113||113|0|2|3|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|2\n",
      "30|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|1|7/5 = y+7|2005-09-09 12:37:01.0|2005-09-09 12:37:09.0|2005-09-09 12:37:09.0|2005-09-09 12:37:09.0|8|8||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|10\n",
      "31|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|2|-7(x+9) = -5|2005-09-09 12:37:17.0|2005-09-09 12:38:15.0|2005-09-09 12:38:15.0|2005-09-09 12:38:15.0|58|58||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|3\n",
      "32|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|2|x+9 = 5/7|2005-09-09 12:38:15.0|2005-09-09 12:38:21.0|2005-09-09 12:38:21.0|2005-09-09 12:38:21.0|6|6||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|11\n",
      "33|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|3|5 = 8(y+1)|2005-09-09 12:38:25.0|2005-09-09 12:38:33.0|2005-09-09 12:38:33.0|2005-09-09 12:38:33.0|8|8||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|4\n",
      "34|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|3|5/8 = y+1|2005-09-09 12:38:33.0|2005-09-09 12:38:40.0|2005-09-09 12:38:40.0|2005-09-09 12:38:40.0|7|7||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|12\n",
      "35|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|4|0 = -3(x-5)|2005-09-09 12:38:44.0|2005-09-09 12:38:49.0|2005-09-09 12:38:49.0|2005-09-09 12:38:49.0|5|5||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|5\n",
      "36|0BrbPbwCMz|Unit ES_04, Section ES_04-3|EG54|4|0 = x-5|2005-09-09 12:38:49.0|2005-09-09 12:38:56.0|2005-09-09 12:38:56.0|2005-09-09 12:38:56.0|7|7||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|13~~1\n",
      "37|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|-5(y-10) = 3|2005-09-09 12:39:01.0|2005-09-09 12:39:07.0|2005-09-09 12:39:07.0|2005-09-09 12:39:07.0|6|6||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|6\n",
      "38|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|-5(y-10)/-5 = 3/-5|2005-09-09 12:39:07.0|2005-09-09 12:39:13.0|2005-09-09 12:39:13.0|2005-09-09 12:39:18.0|11|11||1|0|0|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|1\n",
      "39|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|y-10 = 3/-5|2005-09-09 12:39:18.0|2005-09-09 12:39:26.0|2005-09-09 12:39:26.0|2005-09-09 12:39:26.0|8|8||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|14\n",
      "40|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|y-10+10 = 3/-5+10|2005-09-09 12:39:26.0|2005-09-09 12:39:29.0|2005-09-09 12:39:29.0|2005-09-09 12:39:36.0|10|10||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|5\n",
      "41|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|y = 3/-5+10|2005-09-09 12:39:36.0|2005-09-09 12:39:44.0|2005-09-09 12:40:14.0|2005-09-09 12:40:14.0|38||38|0|1|3|1||\n",
      "42|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|FinalAnswer|2005-09-09 12:40:14.0|2005-09-09 12:40:36.0|2005-09-09 12:40:36.0|2005-09-09 12:41:14.0|39|39||1|0|0|2|simplify-fractions-sp~~combine-like-terms-sp|1~~2\n",
      "43|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|1|y = -3/5+10|2005-09-09 12:40:36.0|2005-09-09 12:40:57.0|2005-09-09 12:40:57.0|2005-09-09 12:40:57.0|21|21||1|0|0|1|[SkillRule: Consolidate vars, no coeff; CLT]|1\n",
      "44|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|4(x-4) = -8|2005-09-09 12:41:48.0|2005-09-09 12:42:13.0|2005-09-09 12:42:13.0|2005-09-09 12:42:13.0|25|25||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|7\n",
      "45|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|4(x-4)/4 = -8/4|2005-09-09 12:42:13.0|2005-09-09 12:42:18.0|2005-09-09 12:42:18.0|2005-09-09 12:42:23.0|10|10||1|0|0|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|2\n",
      "46|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|x-4 = -8/4|2005-09-09 12:42:23.0|2005-09-09 12:42:32.0|2005-09-09 12:42:32.0|2005-09-09 12:42:32.0|9|9||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|15\n",
      "47|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|x-4+4 = -8/4+4|2005-09-09 12:42:32.0|2005-09-09 12:42:35.0|2005-09-09 12:42:35.0|2005-09-09 12:42:55.0|23|23||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|6\n",
      "48|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|x = -8/4+4|2005-09-09 12:42:55.0|2005-09-09 12:43:02.0|2005-09-09 12:43:02.0|2005-09-09 12:43:02.0|7|7||1|0|0|1|[SkillRule: Consolidate vars, no coeff; CLT]|2\n",
      "49|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|2|FinalAnswer|2005-09-09 12:43:02.0|2005-09-09 12:43:25.0|2005-09-09 12:43:25.0|2005-09-09 12:43:25.0|23|23||1|0|0|1|simplify-fractions-sp~~combine-like-terms-sp|2~~3\n",
      "50|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|5 = 4(x-3)|2005-09-09 12:43:34.0|2005-09-09 12:43:41.0|2005-09-09 12:43:41.0|2005-09-09 12:43:41.0|7|7||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|8\n",
      "51|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|5/4 = 4(x-3)/4|2005-09-09 12:43:41.0|2005-09-09 12:43:45.0|2005-09-09 12:43:45.0|2005-09-09 12:43:49.0|8|8||1|0|0|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|3\n",
      "52|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|5/4 = x-3|2005-09-09 12:43:49.0|2005-09-09 12:44:09.0|2005-09-09 12:44:09.0|2005-09-09 12:44:09.0|20|20||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|16\n",
      "53|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|5/4+3 = x-3+3|2005-09-09 12:44:09.0|2005-09-09 12:44:12.0|2005-09-09 12:44:12.0|2005-09-09 12:44:19.0|10|10||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|7\n",
      "54|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|5/4+3 = x|2005-09-09 12:44:19.0|2005-09-09 12:44:35.0|2005-09-09 12:44:35.0|2005-09-09 12:44:35.0|16|16||1|0|0|1|[SkillRule: Consolidate vars, no coeff; CLT]|3\n",
      "55|0BrbPbwCMz|Unit ES_04, Section ES_04-4|EG54|3|FinalAnswer|2005-09-09 12:44:35.0|2005-09-09 12:44:48.0|2005-09-09 12:44:48.0|2005-09-09 12:44:48.0|13|13||1|0|0|1|simplify-fractions-sp~~combine-like-terms-sp|3~~4\n",
      "56|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55A|1|0.1 = -42.3(y-83.7)|2005-09-09 12:44:58.0|2005-09-09 12:45:42.0|2005-09-09 12:45:42.0|2005-09-09 12:45:42.0|44|44||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|9\n",
      "57|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55A|1|-0.00236407 = y-83.7|2005-09-09 12:45:42.0|2005-09-09 12:45:56.0|2005-09-09 12:45:56.0|2005-09-09 12:45:56.0|14|14||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|17~~2\n",
      "58|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|1|1.8(y-9.8) = -2.4|2005-09-09 12:46:01.0|2005-09-09 12:46:48.0|2005-09-09 12:46:57.0|2005-09-09 12:46:57.0|56||56|0|1|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|10\n",
      "59|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|1|y-9.8 = -1.33333333|2005-09-09 12:46:57.0|2005-09-09 12:47:49.0|2005-09-09 12:48:21.0|2005-09-09 12:48:21.0|84||84|0|1|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|18~~3\n",
      "60|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|2|-5.5(y-1.9) = -9.6|2005-09-09 12:48:26.0|2005-09-09 12:49:24.0|2005-09-09 12:49:24.0|2005-09-09 12:49:24.0|58|58||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|11\n",
      "61|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|2|y-1.9 = 1.74545455|2005-09-09 12:49:24.0|2005-09-09 12:51:10.0||2005-09-09 12:51:17.0|113||113|0|2|0|0|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|19~~4\n",
      "62|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|3|0.1(x+3.9) = -3.9|2005-09-14 12:15:07.0|2005-09-14 12:15:34.0|2005-09-14 12:16:19.0|2005-09-14 12:16:19.0|72||72|0|3|3|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|12\n",
      "63|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|3|x+3.9 = -39|2005-09-14 12:16:19.0|2005-09-14 12:17:00.0|2005-09-14 12:17:00.0|2005-09-14 12:17:00.0|41|41||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate positive; x+a=b, positive]|20~~2\n",
      "64|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55A|2|-66.4(y-73.3) = 2.6|2005-09-14 12:17:10.0|2005-09-14 12:17:25.0|2005-09-14 12:17:25.0|2005-09-14 12:17:25.0|15|15||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|13\n",
      "65|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55A|2|y-73.3 = -0.03915663|2005-09-14 12:17:25.0|2005-09-14 12:17:37.0|2005-09-14 12:17:48.0|2005-09-14 12:17:48.0|23||23|0|1|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|21~~5\n",
      "66|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|4|9.2 = -3.4(y-6.7)|2005-09-14 12:17:52.0|2005-09-14 12:18:01.0|2005-09-14 12:18:13.0|2005-09-14 12:18:13.0|21||21|0|1|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|14\n",
      "67|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|4|-2.70588235 = y-6.7|2005-09-14 12:18:13.0|2005-09-14 12:18:42.0|2005-09-14 12:18:42.0|2005-09-14 12:18:42.0|29|29||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|22~~6\n",
      "68|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|5|2.6 = 6.6(x-1.2)|2005-09-14 12:18:48.0|2005-09-14 12:19:00.0|2005-09-14 12:19:00.0|2005-09-14 12:19:00.0|12|12||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|15\n",
      "69|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|5|0.39393939 = x-1.2|2005-09-14 12:19:00.0|2005-09-14 12:19:07.0|2005-09-14 12:19:07.0|2005-09-14 12:19:07.0|7|7||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate negative; x+a=b, negative]|23~~7\n",
      "70|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|6|0.3(y+4.4) = 6.5|2005-09-14 12:19:12.0|2005-09-14 12:19:56.0|2005-09-14 12:19:56.0|2005-09-14 12:19:56.0|44|44||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|16\n",
      "71|0BrbPbwCMz|Unit ES_04, Section ES_04-5|EG55|6|y+4.4 = 21.66666667|2005-09-14 12:19:56.0|2005-09-14 12:20:04.0|2005-09-14 12:20:04.0|2005-09-14 12:20:04.0|8|8||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]~~[SkillRule: Isolate positive; x+a=b, positive]|24~~3\n",
      "72|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|-6.6(y+6.9) = 7.8|2005-09-14 12:20:12.0|2005-09-14 12:20:48.0|2005-09-14 12:20:48.0|2005-09-14 12:20:48.0|36|36||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|17\n",
      "73|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|-6.6(y+6.9)/-6.6 = 7.8/-6.6|2005-09-14 12:20:48.0|2005-09-14 12:20:57.0|2005-09-14 12:20:57.0|2005-09-14 12:21:10.0|22|22||1|0|0|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|4\n",
      "74|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|y+6.9 = 7.8/-6.6|2005-09-14 12:21:10.0|2005-09-14 12:21:17.0|2005-09-14 12:21:17.0|2005-09-14 12:21:17.0|7|7||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|25\n",
      "75|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|y+6.9-6.9 = 7.8/-6.6-6.9|2005-09-14 12:21:17.0|2005-09-14 12:21:21.0|2005-09-14 12:21:21.0|2005-09-14 12:22:58.0|101|101||1|3|2|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|8\n",
      "76|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|y = 7.8/-6.6-6.9|2005-09-14 12:22:58.0|2005-09-14 12:23:10.0|2005-09-14 12:24:47.0|2005-09-14 12:24:47.0|109||109|0|2|2|1||\n",
      "77|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|FinalAnswer|2005-09-14 12:24:47.0|2005-09-14 12:25:48.0|2005-09-14 12:25:48.0|2005-09-14 12:26:47.0|82|82||1|0|0|2|simplify-fractions-sp~~combine-like-terms-sp|4~~5\n",
      "78|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55|1|y = -1.1818-6.9|2005-09-14 12:25:48.0|2005-09-14 12:26:01.0|2005-09-14 12:26:26.0|2005-09-14 12:26:26.0|38||38|0|2|2|1|[SkillRule: Select Combine Terms; CLT]~~[SkillRule: Consolidate vars, no coeff; CLT]|1~~4\n",
      "79|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-2 = 94.4(x+1.8)|2005-09-14 12:26:55.0|2005-09-14 12:27:57.0|2005-09-14 12:27:57.0|2005-09-14 12:38:55.0|643|643||1|4|1|3|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|18\n",
      "80|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-2/94.4 = 94.4(x+1.8)/94.4|2005-09-14 12:27:57.0|2005-09-14 12:28:13.0|2005-09-14 12:29:29.0|2005-09-14 12:30:07.0|77||77|0|3|2|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|5\n",
      "81|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|FinalAnswer|2005-09-14 12:38:55.0|2005-09-14 12:39:45.0|2005-09-14 12:39:45.0|2005-09-14 12:47:16.0|105|105||1|1|0|4|distribute-sp~~simplify-fractions-sp~~combine-like-terms-sp|1~~5~~6\n",
      "82|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-2 = 94.4x+169.92|2005-09-14 12:39:45.0|2005-09-14 12:40:01.0|2005-09-14 12:41:18.0|2005-09-14 12:41:18.0|93||93|0|1|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|26\n",
      "83|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-2-169.92 = 94.4x+169.92-169.92|2005-09-14 12:41:18.0|2005-09-14 12:41:29.0|2005-09-14 12:41:29.0|2005-09-14 12:42:47.0|89|89||1|3|0|3|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]~~[SkillRule: Consolidate vars with coeff; CLT]|9~~2\n",
      "84|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-171.92 = 94.4x+169.92-169.92|2005-09-14 12:43:17.0|2005-09-14 12:43:29.0|2005-09-14 12:43:29.0|2005-09-14 12:43:29.0|12|12||1|0|0|1|[SkillRule: Consolidate vars with coeff; CLT]|3\n",
      "85|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|x1R1|2005-09-14 12:43:29.0|2005-09-14 12:44:32.0|2005-09-14 12:44:32.0|2005-09-14 12:44:32.0|63|63||1|0|0|1||\n",
      "86|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|constant terms1R1|2005-09-14 12:44:32.0|2005-09-14 12:44:41.0|2005-09-14 12:44:41.0|2005-09-14 12:44:41.0|9|9||1|0|0|1||\n",
      "87|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|constant terms2R1|2005-09-14 12:44:41.0|2005-09-14 12:44:45.0|2005-09-14 12:44:45.0|2005-09-14 12:44:45.0|4|4||1|0|0|1||\n",
      "88|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|xR2|2005-09-14 12:44:45.0|2005-09-14 12:44:59.0|2005-09-14 12:44:59.0|2005-09-14 12:44:59.0|14|14||1|0|0|1||\n",
      "89|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-171.92 = 94.4x+0|2005-09-14 12:45:04.0|2005-09-14 12:46:49.0|2005-09-14 12:46:56.0|2005-09-14 12:46:56.0|112||112|0|1|2|1|[SkillRule: Consolidate vars with coeff; CLT]|4\n",
      "90|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-171.92 = 94.4x|2005-09-14 12:47:16.0|2005-09-14 12:47:35.0|2005-09-14 12:47:35.0|2005-09-14 12:47:35.0|19|19||1|0|0|1|[SkillRule: Remove positive coefficient; {ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b}]~~[SkillRule: Remove coefficient; {ax+b=c, divide; ax=b; [const expr]*[var fact] + [const expr] = [const expr], divide; [var expr]*[const expr] = [const expr], divide; a/b*x=c; a/b*x=c, reciprocal; ax/b=c, reciprocal; ax/b=c; x/a=b; ax=b; (+/-x +/-a)/b=c, mult; a=x*(b+c); a=x*(b-c); a=x*(b*c+d); x/a+b=c, multiply; [var expr]/[const expr] = [const expr], multiply}]|5~~9\n",
      "91|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|1|-171.92/94.4 = 94.4x/94.4|2005-09-14 12:47:35.0|2005-09-14 12:47:39.0|2005-09-14 12:47:39.0|2005-09-14 12:47:51.0|16|16||1|0|0|2|[SkillRule: Multiply/Divide; [Typein Skill: {Remove coefficient; Variable in denominator}]]|5\n",
      "92|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|2|66.8(y+68.4) = -2.8|2005-09-14 12:47:56.0|2005-09-14 12:48:29.0|2005-09-14 12:48:29.0|2005-09-14 12:48:29.0|33|33||1|0|0|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|19\n",
      "93|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|2|FinalAnswer|2005-09-14 12:48:29.0|2005-09-14 12:49:10.0|2005-09-14 12:49:10.0|2005-09-14 12:49:10.0|41|41||1|0|0|1|distribute-sp~~simplify-fractions-sp~~combine-like-terms-sp|2~~6~~7\n",
      "94|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|2|66.8y+4569.12 = -2.8|2005-09-14 12:49:10.0|2005-09-14 12:49:31.0|2005-09-14 12:49:31.0|2005-09-14 12:49:31.0|21|21||1|0|0|1|[SkillRule: Remove constant; {ax+b=c, positive; ax+b=c, negative; x+a=b, positive; x+a=b, negative; [var expr]+[const expr]=[const expr], positive; [var expr]+[const expr]=[const expr], negative; [var expr]+[const expr]=[const expr], all; Combine constants to right; Combine constants to left; a-x=b, positive; a/x+b=c, positive; a/x+b=c, negative}]|27\n",
      "95|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|2|66.8y+4569.12-4569.12 = -2.8-4569.12|2005-09-14 12:49:31.0|2005-09-14 12:49:39.0|2005-09-14 12:49:39.0|2005-09-14 12:49:54.0|23|23||1|0|0|2|[SkillRule: Add/Subtract; [Typein Skill: {Isolate positive; Isolate negative; Remove constant; Consolidate vars, no coeff; Consolidate vars with coeff; Consolidate vars, any}]]|10\n",
      "96|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|3|-29.5(y-6.2) = 8.7|2005-09-16 12:16:46.0|2005-09-16 12:21:34.0|2005-09-16 12:22:30.0|2005-09-16 12:22:30.0|344||344|0|3|3|1|[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]|20\n",
      "97|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|3|-29.5(y-6.2)/-29.5 = 8.7/-29.5|2005-09-16 12:22:30.0|2005-09-16 12:22:44.0|2005-09-16 12:22:44.0|2005-09-16 12:23:00.0|30|30||1|0|0|2|[SkillRule: Calculate Eliminate Parens; [Typein Skill: Eliminate Parens]]|6\n",
      "98|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|3|y-6.2 = 8.7/-29.5|2005-09-16 12:23:00.0|2005-09-16 12:23:07.0|2005-09-16 12:23:14.0|2005-09-16 12:23:14.0|14||14|0|0|2|1||\n",
      "99|0BrbPbwCMz|Unit ES_04, Section ES_04-6|EG55A|3|FinalAnswer|2005-09-16 12:23:14.0|2005-09-16 12:23:49.0|2005-09-16 12:24:57.0|2005-09-16 12:24:57.0|103||103|0|1|0|1|distribute-sp~~simplify-fractions-sp~~combine-like-terms-sp|3~~7~~8\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "i = 0\n",
    "\n",
    "with open('algebra_2005_2006/algebra_2005_2006_train.csv') as csvfile:\n",
    "    filereader = csv.reader(csvfile, delimiter='\\t', quotechar=\"|\")\n",
    "    \n",
    "    for row in filereader:\n",
    "        print \"|\".join(row)\n",
    "        i += 1\n",
    "        if i == 100:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'variable_scope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-76cf60071201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m \u001b[0mrnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_previous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-76cf60071201>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(feed_previous)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mfeed_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_previous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-76cf60071201>\u001b[0m in \u001b[0;36m_basic_rnn_seq2seq\u001b[0;34m(encoder_inputs, decoder_inputs, cell, feed_previous, scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mIt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0mx\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m           \"\"\"\n\u001b[0;32m--> 159\u001b[0;31m           \u001b[0;32mwith\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"basic_rnn_seq2seq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0menc_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'variable_scope' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "x = np.linspace(0, 30, 105)\n",
    "y = 2 * np.sin(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "lambda_l2_reg = 0.003  \n",
    "\n",
    "## Network Parameters\n",
    "# length of input signals\n",
    "input_seq_len = 15 \n",
    "# length of output signals\n",
    "output_seq_len = 20 \n",
    "# size of LSTM Cell\n",
    "hidden_dim = 64 \n",
    "# num of input signals\n",
    "input_dim = 1\n",
    "# num of output signals\n",
    "output_dim = 1\n",
    "# num of stacked lstm layers \n",
    "num_stacked_layers = 2 \n",
    "# gradient clipping - to avoid gradient exploding\n",
    "GRADIENT_CLIPPING = 2.5 \n",
    "\n",
    "total_iteractions = 100\n",
    "batch_size = 16\n",
    "KEEP_RATE = 0.5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "x = np.linspace(0, 30, 105)\n",
    "train_data_x = x[:85]\n",
    "\n",
    "\n",
    "def build_graph(feed_previous = False):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.Variable(\n",
    "                  initial_value=0,\n",
    "                  name=\"global_step\",\n",
    "                  trainable=False,\n",
    "                  collections=[tf.GraphKeys.GLOBAL_STEP, tf.GraphKeys.GLOBAL_VARIABLES])\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.get_variable('Weights_out', \\\n",
    "                               shape = [hidden_dim, output_dim], \\\n",
    "                               dtype = tf.float32, \\\n",
    "                               initializer = tf.truncated_normal_initializer()),\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.get_variable('Biases_out', \\\n",
    "                               shape = [output_dim], \\\n",
    "                               dtype = tf.float32, \\\n",
    "                               initializer = tf.constant_initializer(0.)),\n",
    "    }\n",
    "\n",
    "    with tf.variable_scope('Seq2seq'):\n",
    "        # Encoder: inputs\n",
    "        enc_inp = [\n",
    "            tf.placeholder(tf.float32, shape=(None, input_dim), name=\"inp_{}\".format(t))\n",
    "               for t in range(input_seq_len)\n",
    "        ]\n",
    "\n",
    "        # Decoder: target outputs\n",
    "        target_seq = [\n",
    "            tf.placeholder(tf.float32, shape=(None, output_dim), name=\"y\".format(t))\n",
    "              for t in range(output_seq_len)\n",
    "        ]\n",
    "\n",
    "        # Give a \"GO\" token to the decoder. \n",
    "        # If dec_inp are fed into decoder as inputs, this is 'guided' training; otherwise only the \n",
    "        # first element will be fed as decoder input which is then 'un-guided'\n",
    "        dec_inp = [ tf.zeros_like(target_seq[0], dtype=tf.float32, name=\"GO\") ] + target_seq[:-1]\n",
    "\n",
    "        with tf.variable_scope('LSTMCell'): \n",
    "            cells = []\n",
    "            for i in range(num_stacked_layers):\n",
    "                with tf.variable_scope('RNN_{}'.format(i)):\n",
    "                    cells.append(tf.contrib.rnn.LSTMCell(hidden_dim))\n",
    "            cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "        def _rnn_decoder(decoder_inputs,\n",
    "                        initial_state,\n",
    "                        cell,\n",
    "                        loop_function=None,\n",
    "                        scope=None):\n",
    "          \"\"\"RNN decoder for the sequence-to-sequence model.\n",
    "          Args:\n",
    "            decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
    "            initial_state: 2D Tensor with shape [batch_size x cell.state_size].\n",
    "            cell: rnn_cell.RNNCell defining the cell function and size.\n",
    "            loop_function: If not None, this function will be applied to the i-th output\n",
    "              in order to generate the i+1-st input, and decoder_inputs will be ignored,\n",
    "              except for the first element (\"GO\" symbol). This can be used for decoding,\n",
    "              but also for training to emulate http://arxiv.org/abs/1506.03099.\n",
    "              Signature -- loop_function(prev, i) = next\n",
    "                * prev is a 2D Tensor of shape [batch_size x output_size],\n",
    "                * i is an integer, the step number (when advanced control is needed),\n",
    "                * next is a 2D Tensor of shape [batch_size x input_size].\n",
    "            scope: VariableScope for the created subgraph; defaults to \"rnn_decoder\".\n",
    "          Returns:\n",
    "            A tuple of the form (outputs, state), where:\n",
    "              outputs: A list of the same length as decoder_inputs of 2D Tensors with\n",
    "                shape [batch_size x output_size] containing generated outputs.\n",
    "              state: The state of each cell at the final time-step.\n",
    "                It is a 2D Tensor of shape [batch_size x cell.state_size].\n",
    "                (Note that in some cases, like basic RNN cell or GRU cell, outputs and\n",
    "                 states can be the same. They are different for LSTM cells though.)\n",
    "          \"\"\"\n",
    "          with variable_scope.variable_scope(scope or \"rnn_decoder\"):\n",
    "            state = initial_state\n",
    "            outputs = []\n",
    "            prev = None\n",
    "            for i, inp in enumerate(decoder_inputs):\n",
    "              if loop_function is not None and prev is not None:\n",
    "                with variable_scope.variable_scope(\"loop_function\", reuse=True):\n",
    "                  inp = loop_function(prev, i)\n",
    "              if i > 0:\n",
    "                variable_scope.get_variable_scope().reuse_variables()\n",
    "              output, state = cell(inp, state)\n",
    "              outputs.append(output)\n",
    "              if loop_function is not None:\n",
    "                prev = output\n",
    "          return outputs, state\n",
    "\n",
    "        def _basic_rnn_seq2seq(encoder_inputs,\n",
    "                              decoder_inputs,\n",
    "                              cell,\n",
    "                              feed_previous,\n",
    "                              #dtype=dtypes.float32,\n",
    "                              scope=None):\n",
    "          \"\"\"Basic RNN sequence-to-sequence model.\n",
    "          This model first runs an RNN to encode encoder_inputs into a state vector,\n",
    "          then runs decoder, initialized with the last encoder state, on decoder_inputs.\n",
    "          Encoder and decoder use the same RNN cell type, but don't share parameters.\n",
    "          Args:\n",
    "            encoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
    "            decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
    "            feed_previous: Boolean; if True, only the first of decoder_inputs will be\n",
    "              used (the \"GO\" symbol), all other inputs will be generated by the previous \n",
    "              decoder output using _loop_function below. If False, decoder_inputs are used \n",
    "              as given (the standard decoder case).\n",
    "            dtype: The dtype of the initial state of the RNN cell (default: tf.float32).\n",
    "            scope: VariableScope for the created subgraph; default: \"basic_rnn_seq2seq\".\n",
    "          Returns:\n",
    "            A tuple of the form (outputs, state), where:\n",
    "              outputs: A list of the same length as decoder_inputs of 2D Tensors with\n",
    "                shape [batch_size x output_size] containing the generated outputs.\n",
    "              state: The state of each decoder cell in the final time-step.\n",
    "                It is a 2D Tensor of shape [batch_size x cell.state_size].\n",
    "          \"\"\"\n",
    "          with variable_scope.variable_scope(scope or \"basic_rnn_seq2seq\"):\n",
    "            enc_cell = copy.deepcopy(cell)\n",
    "            _, enc_state = rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)\n",
    "            if feed_previous:\n",
    "                return _rnn_decoder(decoder_inputs, enc_state, cell, _loop_function)\n",
    "            else:\n",
    "                return _rnn_decoder(decoder_inputs, enc_state, cell)\n",
    "\n",
    "        def _loop_function(prev, _):\n",
    "          '''Naive implementation of loop function for _rnn_decoder. Transform prev from \n",
    "          dimension [batch_size x hidden_dim] to [batch_size x output_dim], which will be\n",
    "          used as decoder input of next time step '''\n",
    "          return tf.matmul(prev, weights['out']) + biases['out']\n",
    "\n",
    "        dec_outputs, dec_memory = _basic_rnn_seq2seq(\n",
    "            enc_inp, \n",
    "            dec_inp, \n",
    "            cell, \n",
    "            feed_previous = feed_previous\n",
    "        )\n",
    "\n",
    "        reshaped_outputs = [tf.matmul(i, weights['out']) + biases['out'] for i in dec_outputs]\n",
    "\n",
    "    # Training loss and optimizer\n",
    "    with tf.variable_scope('Loss'):\n",
    "        # L2 loss\n",
    "        output_loss = 0\n",
    "        for _y, _Y in zip(reshaped_outputs, target_seq):\n",
    "            output_loss += tf.reduce_mean(tf.pow(_y - _Y, 2))\n",
    "\n",
    "        # L2 regularization for weights and biases\n",
    "        reg_loss = 0\n",
    "        for tf_var in tf.trainable_variables():\n",
    "            if 'Biases_' in tf_var.name or 'Weights_' in tf_var.name:\n",
    "                reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))\n",
    "\n",
    "        loss = output_loss + lambda_l2_reg * reg_loss\n",
    "\n",
    "    with tf.variable_scope('Optimizer'):\n",
    "        optimizer = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                learning_rate=learning_rate,\n",
    "                global_step=global_step,\n",
    "                optimizer='Adam',\n",
    "                clip_gradients=GRADIENT_CLIPPING)\n",
    "\n",
    "    saver = tf.train.Saver\n",
    "\n",
    "    return dict(\n",
    "        enc_inp = enc_inp, \n",
    "        target_seq = target_seq, \n",
    "        train_op = optimizer, \n",
    "        loss=loss,\n",
    "        saver = saver, \n",
    "        reshaped_outputs = reshaped_outputs,\n",
    "        )\n",
    "\n",
    "\n",
    "rnn_model = build_graph(feed_previous=False)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(total_iteractions):\n",
    "        batch_input, batch_output = generate_train_samples(batch_size=batch_size)\n",
    "\n",
    "        feed_dict = {rnn_model['enc_inp'][t]: batch_input[:,t].reshape(-1,input_dim) for t in range(input_seq_len)}\n",
    "        feed_dict.update({rnn_model['target_seq'][t]: batch_output[:,t].reshape(-1,output_dim) for t in range(output_seq_len)})\n",
    "        _, loss_t = sess.run([rnn_model['train_op'], rnn_model['loss']], feed_dict)\n",
    "        print(loss_t)\n",
    "\n",
    "    #temp_saver = rnn_model['saver']()\n",
    "    #save_path = temp_saver.save(sess, os.path.join('./', 'univariate_ts_model0'))\n",
    "\n",
    "#print(\"Checkpoint saved at: \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "i = 0\n",
    "\n",
    "all_data = []\n",
    "training_set = []\n",
    "labels = []\n",
    "testing_set = []\n",
    "\n",
    "with open('algebra_2005_2006/algebra_2005_2006_train.csv') as csvfile:\n",
    "    filereader = csv.reader(csvfile, delimiter='\\t', quotechar=\"|\")\n",
    "    \n",
    "    for row in filereader:\n",
    "        \n",
    "        if i > 0:\n",
    "            train_data = []\n",
    "            train_data.append(float(row[10]))\n",
    "            train_data.append(float(row[14]))\n",
    "            train_data.append(float(row[15]))\n",
    "            train_data.append(float(row[16]))\n",
    "            train_data = np.asarray(train_data)\n",
    "            label = np.asarray(row[13])\n",
    "            all_data.append(train_data)\n",
    "            labels.append(label)\n",
    "        \n",
    "        i += 1\n",
    "        if i == 1001:\n",
    "            break\n",
    "all_data = np.asarray(all_data)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "training_set = all_data[:900]\n",
    "testing_set = all_data[900:]\n",
    "\n",
    "training_label = labels[:900]\n",
    "testing_label = labels[900:]\n",
    "\n",
    "print training_set[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 16:46:47.396384 140171748357888 deprecation.py:323] From <ipython-input-1-94bae3a83e40>:73: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0628 16:46:47.398016 140171748357888 deprecation.py:323] From <ipython-input-1-94bae3a83e40>:76: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W0628 16:46:47.412378 140171748357888 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 16:46:47.419951 140171748357888 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 16:46:47.433743 140171748357888 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 4)\n",
      "(100, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 16:46:48.626055 140171748357888 deprecation.py:323] From <ipython-input-1-94bae3a83e40>:85: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.0000, Training Accuracy= 0.780\n",
      "Step 1, Minibatch Loss= 0.0001, Training Accuracy= 0.880\n",
      "Step 1, Minibatch Loss= 0.0026, Training Accuracy= 0.770\n",
      "Step 1, Minibatch Loss= 0.0018, Training Accuracy= 0.570\n",
      "Step 1, Minibatch Loss= 0.0258, Training Accuracy= 0.660\n",
      "Step 1, Minibatch Loss= 0.7852, Training Accuracy= 0.250\n",
      "Step 1, Minibatch Loss= 0.0009, Training Accuracy= 0.710\n",
      "Step 1, Minibatch Loss= 0.0163, Training Accuracy= 0.600\n",
      "Step 1, Minibatch Loss= 0.0171, Training Accuracy= 0.560\n",
      "Step 200, Minibatch Loss= 0.1109, Training Accuracy= 0.780\n",
      "Step 200, Minibatch Loss= 0.1421, Training Accuracy= 0.880\n",
      "Step 200, Minibatch Loss= 0.0949, Training Accuracy= 0.770\n",
      "Step 200, Minibatch Loss= 0.1181, Training Accuracy= 0.570\n",
      "Step 200, Minibatch Loss= 0.1087, Training Accuracy= 0.660\n",
      "Step 200, Minibatch Loss= 0.1428, Training Accuracy= 0.750\n",
      "Step 200, Minibatch Loss= 0.1149, Training Accuracy= 0.710\n",
      "Step 200, Minibatch Loss= 0.0953, Training Accuracy= 0.600\n",
      "Step 200, Minibatch Loss= 0.0849, Training Accuracy= 0.560\n",
      "Step 400, Minibatch Loss= 0.1282, Training Accuracy= 0.780\n",
      "Step 400, Minibatch Loss= 0.1393, Training Accuracy= 0.880\n",
      "Step 400, Minibatch Loss= 0.1244, Training Accuracy= 0.770\n",
      "Step 400, Minibatch Loss= 0.0936, Training Accuracy= 0.570\n",
      "Step 400, Minibatch Loss= 0.1063, Training Accuracy= 0.660\n",
      "Step 400, Minibatch Loss= 0.1165, Training Accuracy= 0.750\n",
      "Step 400, Minibatch Loss= 0.1215, Training Accuracy= 0.710\n",
      "Step 400, Minibatch Loss= 0.0932, Training Accuracy= 0.600\n",
      "Step 400, Minibatch Loss= 0.1020, Training Accuracy= 0.560\n",
      "Step 600, Minibatch Loss= 0.1290, Training Accuracy= 0.780\n",
      "Step 600, Minibatch Loss= 0.1415, Training Accuracy= 0.880\n",
      "Step 600, Minibatch Loss= 0.1240, Training Accuracy= 0.770\n",
      "Step 600, Minibatch Loss= 0.0934, Training Accuracy= 0.570\n",
      "Step 600, Minibatch Loss= 0.1075, Training Accuracy= 0.660\n",
      "Step 600, Minibatch Loss= 0.1202, Training Accuracy= 0.750\n",
      "Step 600, Minibatch Loss= 0.1182, Training Accuracy= 0.710\n",
      "Step 600, Minibatch Loss= 0.0960, Training Accuracy= 0.600\n",
      "Step 600, Minibatch Loss= 0.0972, Training Accuracy= 0.560\n",
      "Step 800, Minibatch Loss= 0.1291, Training Accuracy= 0.780\n",
      "Step 800, Minibatch Loss= 0.1419, Training Accuracy= 0.880\n",
      "Step 800, Minibatch Loss= 0.1238, Training Accuracy= 0.770\n",
      "Step 800, Minibatch Loss= 0.0931, Training Accuracy= 0.570\n",
      "Step 800, Minibatch Loss= 0.1083, Training Accuracy= 0.660\n",
      "Step 800, Minibatch Loss= 0.1210, Training Accuracy= 0.750\n",
      "Step 800, Minibatch Loss= 0.1172, Training Accuracy= 0.710\n",
      "Step 800, Minibatch Loss= 0.0971, Training Accuracy= 0.600\n",
      "Step 800, Minibatch Loss= 0.0958, Training Accuracy= 0.560\n",
      "Step 1000, Minibatch Loss= 0.1289, Training Accuracy= 0.780\n",
      "Step 1000, Minibatch Loss= 0.1419, Training Accuracy= 0.880\n",
      "Step 1000, Minibatch Loss= 0.1237, Training Accuracy= 0.770\n",
      "Step 1000, Minibatch Loss= 0.0930, Training Accuracy= 0.570\n",
      "Step 1000, Minibatch Loss= 0.1089, Training Accuracy= 0.660\n",
      "Step 1000, Minibatch Loss= 0.1214, Training Accuracy= 0.750\n",
      "Step 1000, Minibatch Loss= 0.1167, Training Accuracy= 0.710\n",
      "Step 1000, Minibatch Loss= 0.0977, Training Accuracy= 0.600\n",
      "Step 1000, Minibatch Loss= 0.0953, Training Accuracy= 0.560\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94bae3a83e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_label' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import csv\n",
    "i = 0\n",
    "\n",
    "all_data = []\n",
    "training_set = []\n",
    "labels = []\n",
    "testing_set = []\n",
    "\n",
    "with open('algebra_2005_2006/algebra_2005_2006_train.csv') as csvfile:\n",
    "    filereader = csv.reader(csvfile, delimiter='\\t', quotechar=\"|\")\n",
    "    \n",
    "    for row in filereader:\n",
    "        \n",
    "        if i > 0:\n",
    "            train_data = []\n",
    "            train_data.append(float(row[10]))\n",
    "            train_data.append(float(row[14]))\n",
    "            train_data.append(float(row[15]))\n",
    "            train_data.append(float(row[16]))\n",
    "            train_data = np.asarray(train_data)\n",
    "            label = np.asarray([0, row[13]])\n",
    "            all_data.append(train_data)\n",
    "            labels.append(label)\n",
    "        \n",
    "        i += 1\n",
    "        if i == 1001:\n",
    "            break\n",
    "all_data = np.asarray(all_data)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "training_set = all_data[:900]\n",
    "testing_set = all_data[900:]\n",
    "\n",
    "print training_set.shape\n",
    "\n",
    "print training_set[:100].shape\n",
    "\n",
    "training_label = labels[:900]\n",
    "testing_label = labels[900:]\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 1\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 4 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 100 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 2 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.GRUCell(num_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        \n",
    "        for i in range(9):\n",
    "            batch_x = training_set[i*100:i*100 + 100]\n",
    "            batch_y = training_label[i*100:i*100 + 100]\n",
    "            batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                print \"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    test_data = testing_set.reshape(1, timesteps, num_input)\n",
    "    \n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: test_data, Y: testing_label}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
