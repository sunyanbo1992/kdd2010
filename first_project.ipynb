{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'algebra_2005_2006/algebra_2005_2006_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7324fee9e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtesting_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'algebra_2005_2006/algebra_2005_2006_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mfilereader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'algebra_2005_2006/algebra_2005_2006_train.csv'"
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 18:37:39.528215 139647914313472 deprecation.py:323] From <ipython-input-1-f93c4622d0cb>:75: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0628 18:37:39.530121 139647914313472 deprecation.py:323] From <ipython-input-1-f93c4622d0cb>:78: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W0628 18:37:39.561866 139647914313472 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 18:37:39.569473 139647914313472 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 18:37:39.579993 139647914313472 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0628 18:37:49.515497 139647914313472 deprecation.py:323] From <ipython-input-1-f93c4622d0cb>:87: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.0000, Training Accuracy= 0.704\n",
      "Step 1, Minibatch Loss= 0.0002, Training Accuracy= 0.769\n",
      "Step 1, Minibatch Loss= 0.1346, Training Accuracy= 0.693\n",
      "Step 1, Minibatch Loss= 0.1734, Training Accuracy= 0.662\n",
      "Step 1, Minibatch Loss= 0.0609, Training Accuracy= 0.827\n",
      "Step 1, Minibatch Loss= 0.0060, Training Accuracy= 0.847\n",
      "Step 1, Minibatch Loss= 0.0038, Training Accuracy= 0.789\n",
      "Step 1, Minibatch Loss= 0.0184, Training Accuracy= 0.760\n",
      "Step 1, Minibatch Loss= 0.0344, Training Accuracy= 0.734\n",
      "Step 100, Minibatch Loss= 0.1094, Training Accuracy= 0.704\n",
      "Step 100, Minibatch Loss= 0.1115, Training Accuracy= 0.769\n",
      "Step 100, Minibatch Loss= 0.1444, Training Accuracy= 0.693\n",
      "Step 100, Minibatch Loss= 0.1129, Training Accuracy= 0.662\n",
      "Step 100, Minibatch Loss= 0.1463, Training Accuracy= 0.827\n",
      "Step 100, Minibatch Loss= 0.0719, Training Accuracy= 0.847\n",
      "Step 100, Minibatch Loss= 0.1070, Training Accuracy= 0.789\n",
      "Step 100, Minibatch Loss= 0.1044, Training Accuracy= 0.760\n",
      "Step 100, Minibatch Loss= 0.1403, Training Accuracy= 0.734\n",
      "Step 200, Minibatch Loss= 0.1087, Training Accuracy= 0.704\n",
      "Step 200, Minibatch Loss= 0.1067, Training Accuracy= 0.769\n",
      "Step 200, Minibatch Loss= 0.1118, Training Accuracy= 0.693\n",
      "Step 200, Minibatch Loss= 0.1051, Training Accuracy= 0.662\n",
      "Step 200, Minibatch Loss= 0.1279, Training Accuracy= 0.827\n",
      "Step 200, Minibatch Loss= 0.0940, Training Accuracy= 0.847\n",
      "Step 200, Minibatch Loss= 0.0991, Training Accuracy= 0.789\n",
      "Step 200, Minibatch Loss= 0.1028, Training Accuracy= 0.760\n",
      "Step 200, Minibatch Loss= 0.1104, Training Accuracy= 0.734\n",
      "Step 300, Minibatch Loss= 0.0995, Training Accuracy= 0.704\n",
      "Step 300, Minibatch Loss= 0.1047, Training Accuracy= 0.769\n",
      "Step 300, Minibatch Loss= 0.0906, Training Accuracy= 0.693\n",
      "Step 300, Minibatch Loss= 0.0939, Training Accuracy= 0.662\n",
      "Step 300, Minibatch Loss= 0.1166, Training Accuracy= 0.827\n",
      "Step 300, Minibatch Loss= 0.1065, Training Accuracy= 0.847\n",
      "Step 300, Minibatch Loss= 0.1123, Training Accuracy= 0.789\n",
      "Step 300, Minibatch Loss= 0.1006, Training Accuracy= 0.760\n",
      "Step 300, Minibatch Loss= 0.1007, Training Accuracy= 0.734\n",
      "Step 400, Minibatch Loss= 0.0961, Training Accuracy= 0.704\n",
      "Step 400, Minibatch Loss= 0.1029, Training Accuracy= 0.769\n",
      "Step 400, Minibatch Loss= 0.0902, Training Accuracy= 0.693\n",
      "Step 400, Minibatch Loss= 0.0899, Training Accuracy= 0.662\n",
      "Step 400, Minibatch Loss= 0.1106, Training Accuracy= 0.827\n",
      "Step 400, Minibatch Loss= 0.1031, Training Accuracy= 0.847\n",
      "Step 400, Minibatch Loss= 0.1042, Training Accuracy= 0.789\n",
      "Step 400, Minibatch Loss= 0.0987, Training Accuracy= 0.760\n",
      "Step 400, Minibatch Loss= 0.0975, Training Accuracy= 0.734\n",
      "Step 500, Minibatch Loss= 0.0945, Training Accuracy= 0.704\n",
      "Step 500, Minibatch Loss= 0.1022, Training Accuracy= 0.769\n",
      "Step 500, Minibatch Loss= 0.0928, Training Accuracy= 0.693\n",
      "Step 500, Minibatch Loss= 0.0896, Training Accuracy= 0.662\n",
      "Step 500, Minibatch Loss= 0.1090, Training Accuracy= 0.827\n",
      "Step 500, Minibatch Loss= 0.1037, Training Accuracy= 0.847\n",
      "Step 500, Minibatch Loss= 0.1028, Training Accuracy= 0.789\n",
      "Step 500, Minibatch Loss= 0.0982, Training Accuracy= 0.760\n",
      "Step 500, Minibatch Loss= 0.0973, Training Accuracy= 0.734\n",
      "Step 600, Minibatch Loss= 0.0942, Training Accuracy= 0.704\n",
      "Step 600, Minibatch Loss= 0.1019, Training Accuracy= 0.769\n",
      "Step 600, Minibatch Loss= 0.0929, Training Accuracy= 0.693\n",
      "Step 600, Minibatch Loss= 0.0893, Training Accuracy= 0.662\n",
      "Step 600, Minibatch Loss= 0.1091, Training Accuracy= 0.827\n",
      "Step 600, Minibatch Loss= 0.1047, Training Accuracy= 0.847\n",
      "Step 600, Minibatch Loss= 0.1026, Training Accuracy= 0.789\n",
      "Step 600, Minibatch Loss= 0.0984, Training Accuracy= 0.760\n",
      "Step 600, Minibatch Loss= 0.0969, Training Accuracy= 0.734\n",
      "Step 700, Minibatch Loss= 0.0939, Training Accuracy= 0.704\n",
      "Step 700, Minibatch Loss= 0.1018, Training Accuracy= 0.769\n",
      "Step 700, Minibatch Loss= 0.0927, Training Accuracy= 0.693\n",
      "Step 700, Minibatch Loss= 0.0891, Training Accuracy= 0.662\n",
      "Step 700, Minibatch Loss= 0.1092, Training Accuracy= 0.827\n",
      "Step 700, Minibatch Loss= 0.1055, Training Accuracy= 0.847\n",
      "Step 700, Minibatch Loss= 0.1027, Training Accuracy= 0.789\n",
      "Step 700, Minibatch Loss= 0.0985, Training Accuracy= 0.760\n",
      "Step 700, Minibatch Loss= 0.0966, Training Accuracy= 0.734\n",
      "Step 800, Minibatch Loss= 0.0937, Training Accuracy= 0.704\n",
      "Step 800, Minibatch Loss= 0.1016, Training Accuracy= 0.769\n",
      "Step 800, Minibatch Loss= 0.0925, Training Accuracy= 0.693\n",
      "Step 800, Minibatch Loss= 0.0890, Training Accuracy= 0.662\n",
      "Step 800, Minibatch Loss= 0.1093, Training Accuracy= 0.827\n",
      "Step 800, Minibatch Loss= 0.1062, Training Accuracy= 0.847\n",
      "Step 800, Minibatch Loss= 0.1027, Training Accuracy= 0.789\n",
      "Step 800, Minibatch Loss= 0.0986, Training Accuracy= 0.760\n",
      "Step 800, Minibatch Loss= 0.0965, Training Accuracy= 0.734\n",
      "Step 900, Minibatch Loss= 0.0935, Training Accuracy= 0.704\n",
      "Step 900, Minibatch Loss= 0.1015, Training Accuracy= 0.769\n",
      "Step 900, Minibatch Loss= 0.0923, Training Accuracy= 0.693\n",
      "Step 900, Minibatch Loss= 0.0889, Training Accuracy= 0.662\n",
      "Step 900, Minibatch Loss= 0.1093, Training Accuracy= 0.827\n",
      "Step 900, Minibatch Loss= 0.1068, Training Accuracy= 0.847\n",
      "Step 900, Minibatch Loss= 0.1028, Training Accuracy= 0.789\n",
      "Step 900, Minibatch Loss= 0.0987, Training Accuracy= 0.760\n",
      "Step 900, Minibatch Loss= 0.0964, Training Accuracy= 0.734\n",
      "Step 1000, Minibatch Loss= 0.0934, Training Accuracy= 0.704\n",
      "Step 1000, Minibatch Loss= 0.1014, Training Accuracy= 0.769\n",
      "Step 1000, Minibatch Loss= 0.0922, Training Accuracy= 0.693\n",
      "Step 1000, Minibatch Loss= 0.0889, Training Accuracy= 0.662\n",
      "Step 1000, Minibatch Loss= 0.1094, Training Accuracy= 0.827\n",
      "Step 1000, Minibatch Loss= 0.1072, Training Accuracy= 0.847\n",
      "Step 1000, Minibatch Loss= 0.1028, Training Accuracy= 0.789\n",
      "Step 1000, Minibatch Loss= 0.0987, Training Accuracy= 0.760\n",
      "Step 1000, Minibatch Loss= 0.0963, Training Accuracy= 0.734\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [10] vs. [10000]\n\t [[node Equal (defined at <ipython-input-1-f93c4622d0cb>:92) ]]\n\nOriginal stack trace for u'Equal':\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-f93c4622d0cb>\", line 92, in <module>\n    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 3455, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f93c4622d0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtesting_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10] vs. [10000]\n\t [[node Equal (defined at <ipython-input-1-f93c4622d0cb>:92) ]]\n\nOriginal stack trace for u'Equal':\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-f93c4622d0cb>\", line 92, in <module>\n    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 3455, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import csv\n",
    "i = 0\n",
    "\n",
    "all_data = []\n",
    "training_set = []\n",
    "labels = []\n",
    "testing_set = []\n",
    "\n",
    "with open('algebra_2005_2006/algebra_2005_2006_train.csv') as csvfile:\n",
    "    filereader = csv.reader(csvfile, delimiter='\\t', quotechar=\"|\")\n",
    "    \n",
    "    for row in filereader:\n",
    "        \n",
    "        if i > 0:\n",
    "            train_data = []\n",
    "            if len(row[10]) == 0:\n",
    "                train_data.append(0)\n",
    "            else:\n",
    "                train_data.append(float(row[10]))\n",
    "            train_data.append(float(row[14]))\n",
    "            train_data.append(float(row[15]))\n",
    "            train_data.append(float(row[16]))\n",
    "            train_data = np.asarray(train_data)\n",
    "            label = np.asarray([0, 0, row[13]])\n",
    "            all_data.append(train_data)\n",
    "            labels.append(label)\n",
    "        \n",
    "        i += 1\n",
    "        if i == 100001:\n",
    "            break\n",
    "all_data = np.asarray(all_data)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "training_set = all_data[:90000]\n",
    "testing_set = all_data[90000:]\n",
    "\n",
    "training_label = labels[:90000]\n",
    "testing_label = labels[90000:]\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 10\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 4 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 1000 # timesteps\n",
    "num_hidden = 2048 # hidden layer num of features\n",
    "num_hidden = 512 # hidden layer num of features\n",
    "num_classes = 3 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "#seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "#inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "cells = []\n",
    "for _ in range(5):\n",
    "for _ in range(3):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(num_hidden)\n",
    "    #cell = tf.contrib.rnn.AttentionCellWrapper(cell, attn_length = 60, state_is_tuple=True)\n",
    "    cells.append(cell)\n",
    "    \n",
    "stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "#stack = ExtendedMultiRNNCell(cells, residual_connections = False, residual_combiner=\"mean\")\n",
    "outputs, _ = tf.nn.dynamic_rnn(stack, X, dtype=tf.float32)\n",
    "\n",
    "'''\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "    #x = tf.nn.dropout(x, 0.8)\n",
    "    #x = tf.transpose(x, [1, 0, 2])\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    cell = rnn.GRUCell(num_hidden)\n",
    "    #cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=0.8)\n",
    "    #cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 3)\n",
    "    outputs, states = rnn.static_rnn(cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "'''\n",
    "logits = tf.layers.dense(outputs, num_classes)\n",
    "#logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        \n",
    "        for i in xrange(9):\n",
    "            batch_x = training_set[i*10000:i*10000 + 10000]\n",
    "            batch_y = training_label[i*10000:i*10000 + 10000]\n",
    "            batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            right = sess.run(prediction, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "            batch_y = batch_y.reshape(10000, num_classes)\n",
    "            right = right.reshape(10000, num_classes)\n",
    "            count = 0\n",
    "            for j in xrange(len(right)):\n",
    "                if abs(float(right[j][2]) - float(batch_y[j][2])) < 0.1:\n",
    "                    count += 1\n",
    "            acc = count / 10000.0\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss = sess.run(loss_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "                print \"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc)\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    test_data = testing_set.reshape(-1, timesteps, num_input)\n",
    "    \n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: test_data, Y: testing_label}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
